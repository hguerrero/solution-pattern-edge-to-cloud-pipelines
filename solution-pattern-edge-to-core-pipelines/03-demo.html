<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Solution Pattern: Edge to Core Data Pipelines for AI/ML :: Solution Patterns From Red Hat</title>
    <link rel="canonical" href="https://redhat-solution-patterns.github.io/solution-patterns/solution-pattern-edge-to-core-pipelines/03-demo.html">
    <link rel="prev" href="02-architecture.html">
    <link rel="next" href="04-devresources.html">
    <meta name="generator" content="Antora 3.0.0">
    <link rel="stylesheet" href="../_/css/site.css">
<link rel="icon" href="../_/img/favicon.ico" type="image/x-icon">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-SL57MLJENY"></script>
<script>function gtag() { dataLayer.push(arguments) }; window.dataLayer = window.dataLayer || []; gtag('js', new Date()); gtag('config', 'G-SL57MLJENY')</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" style="font-size: 20px; color: white"
        href="https://redhat-solution-patterns.github.io/solution-patterns">
        <img src="../_/img/logo.png" height="35px" alt="Solution Patterns">&nbsp; Solution Patterns From Red Hat</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">Architectures &amp; Patterns</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://www.redhat.com/architect/portfolio/" target="_blank">Portfolio Architecture&nbsp; </a>
            <a class="navbar-item" href="https://redhat-solution-patterns.github.io/solution-patterns/patterns.html"  target="_blank">Solution Patterns </a>
            <a class="navbar-item" href="https://validatedpatterns.io/" target="_blank">Validated Patterns&nbsp;</a>
            <a class="navbar-item" href="https://catalog.redhat.com/solutions" target="_blank">Ecosystem Solutions&nbsp;</a>
          </div>
        </div>

        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">Resources</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" target="_blank" href="https://developers.redhat.com">Red Hat Developers</a>
            <a class="navbar-item" target="_blank" href="https://developers.redhat.com/app-dev-platform">App Dev Platform</a>
            <a class="navbar-item" target="_blank" href="https://www.redhat.com/en/products/application-foundations">Red Hat Application Services</a>
          </div>
        </div>

          <a class="navbar-item" target="_blank" href="https://github.com/redhat-solution-patterns/redhat-solution-patterns.github.io/issues">Feedback</a>
          <a class="navbar-item" target="_blank" href="https://redhat-solution-patterns.github.io/solution-patterns/contributors-guide.html">Contribute</a>

      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="solution-pattern-edge-to-core-pipelines" data-version="master">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="index.html" class=" query-params-link">Edge-to-Core Pipelines: Gather and prepare data for AI/ML</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="index.html">1. Home page</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="index.html#use-cases">1.1 Use cases</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="index.html#_the_story_behind_this_solution_pattern">1.2 The story behind this solution pattern</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="index.html#_the_solution">1.3 The solution</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="02-architecture.html">2. Architecture</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="02-architecture.html#_common_challenges">2.1. Common challenges</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="02-architecture.html#tech_stack">2.2. Technology stack</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="02-architecture.html#in_depth">2.3. An in-depth look at the solution&#8217;s architecture</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="02-architecture.html#_data_acquisition">2.3.1. Data Acquisition</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="02-architecture.html#_data_preparation_modelling">2.3.2. Data Preparation &amp; Modelling</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="02-architecture.html#_application_development_and_delivery">2.3.3. Application Development and Delivery</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="02-architecture.html#_edge_ml_inference">2.3.4. Edge ML Inference</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="02-architecture.html#more_tech">2.4. Additional notes about The Technologies</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="02-architecture.html#_red_hat_service_interconnect">2.4.1. Red Hat Service Interconnect</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="02-architecture.html#_edge_computing">2.4.2 Edge Computing</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="02-architecture.html#_single_node_apache_kafka_broker">2.4.3 Single Node Apache Kafka Broker</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item is-current-page" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="03-demo.html">3. See the Solution in Action</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="#_demonstration">3.4 Demonstration</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="#_recorded_video">3.5 Recorded Video</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="#_install_the_demonstration">3.6. Install the demonstration</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="#_walkthrough_guide">3.7. Walkthrough guide</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="04-devresources.html">4. Developer Resources</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="https://redhat-solution-patterns.github.io/">5. Other Red Hat Solution Patterns</a>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Edge-to-Core Pipelines: Gather and prepare data for AI/ML</span>
    <span class="version">master</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <span class="title">Edge-to-Core Pipelines: Gather and prepare data for AI/ML</span>
      <ul class="versions">
        <li class="version is-current">
          <a href="index.html">master</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="index.html">Edge-to-Core Pipelines: Gather and prepare data for AI/ML</a></li>
    <li><a href="03-demo.html">3. See the Solution in Action</a></li>
  </ul>
</nav>
  <div class="edit-this-page"><a href="https://github.com/redhat-solution-patterns/solution-pattern-edge-to-cloud-pipelines/edit/main/documentation/modules/ROOT/pages/03-demo.adoc">Edit this Page</a></div>
  </div>
  <div class="content">
<article class="doc">
<h1 class="page">Solution Pattern: Edge to Core Data Pipelines for AI/ML</h1>
<h1 id="_see_the_solution_in_action" class="sect0"><a class="anchor" href="#_see_the_solution_in_action"></a><a class="link" href="#_see_the_solution_in_action">See the Solution in Action</a></h1>
<div class="sect1">
<h2 id="_demonstration"><a class="anchor" href="#_demonstration"></a><a class="link" href="#_demonstration">1. Demonstration</a></h2>
<div class="sectionbody">
<div class="paragraph">
<p>The Demo primarily focusses on showcasing how the combination of key Red Hat technologies unlocks the capability of constructing a fully automated platform that chains the full cycle of acquiring data, training models, delivering and deploying models, and run live inferencing.</p>
</div>
<div class="paragraph">
<p>The sections below will help you walk through the essentials of installing and running the demo. But there is much more to discover and extract out of it, among other things:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Customise AI/ML models from publicly available pre-trained models.</p>
</li>
<li>
<p>Create developer-friendly AI/ML models (easy to integrate with).</p>
</li>
<li>
<p>Apply integration technology to move discrete or bulk-based training data.</p>
</li>
<li>
<p>Bridge remote services using Service Interconnect</p>
</li>
<li>
<p>Create scalable architectures growing numbers of edge environments.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_recorded_video"><a class="anchor" href="#_recorded_video"></a><a class="link" href="#_recorded_video">2. Recorded Video</a></h2>
<div class="sectionbody">
<div class="paragraph">
<p>Watch the recorded video of the solution pattern, and find below instructions on how to install the demo and run it.</p>
</div>
<div class="videoblock">
<div class="content">
<iframe width="800" height="480" src="https://www.youtube.com/embed/D7CsGIaKvhc?rel=0" frameborder="0" allowfullscreen></iframe>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_install_the_demonstration"><a class="anchor" href="#_install_the_demonstration"></a><a class="link" href="#_install_the_demonstration">3. Install the demonstration</a></h2>
<div class="sectionbody">
<div class="paragraph">
<p>This Camel Quarkus component combines MQTT and HTTP clients (such as IoT devices, cellphones, and third-party clients) with an AI/ML engine to obtain image detection results.</p>
</div>
<div class="sect2">
<h3 id="_prerequisites"><a class="anchor" href="#_prerequisites"></a><a class="link" href="#_prerequisites">3.1. Prerequisites</a></h3>
<div class="paragraph">
<p>You will require:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>An <em>OpenShift Container Platform</em> cluster running version 4.12 or above with cluster admin access and <em>Red Hat OpenShift AI</em> installed.</p>
</li>
<li>
<p><em>Docker, Podman or Ansible</em> installed and running.<br></p>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
  To run the demo&#8217;s <em>Ansible Playbook</em> to deploy it you&#8217;ll need one of the above. If none of them is installed on your machine we suggest installing <em>Docker</em> using the most recent Docker version. See the <a href="https://docs.docker.com/engine/installation/" target="_blank" rel="noopener">Docker Engine installation documentation</a> for further information.
</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
  You&#8217;ll find more information below on how to use <em>Podman</em> or <em>Ansible</em> as alternatives to <em>Docker</em>.
</td>
</tr>
</table>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p><br></p>
</div>
</div>
<div class="sect2">
<h3 id="_provision_an_openshift_environment"><a class="anchor" href="#_provision_an_openshift_environment"></a><a class="link" href="#_provision_an_openshift_environment">3.2. Provision an OpenShift environment</a></h3>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Provision the following <em>Red Hat Demo Platform</em> (RHDP) item:</p>
<div class="openblock">
<div class="content">
<div class="ulist">
<ul>
<li>
<p><a href="https://demo.redhat.com/catalog?item=babylon-catalog-prod/community-content.com-edge-to-core.prod&amp;utm_source=webapp&amp;utm_medium=share-link" target="_blank" rel="noopener"><strong>Solution Pattern - Edge to Core Data Pipelines for AI/ML</strong></a></p>
<div class="paragraph">
<p><span class="image"><a class="image" href="https://demo.redhat.com/catalog?item=babylon-catalog-prod/community-content.com-edge-to-core.prod&amp;utm_source=webapp&amp;utm_medium=share-link" target="_blank" rel="noopener"><img src="_images/29-rhdp-card.jpg" alt="29 rhdp card" width="30%"></a></span></p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>The provisioning of the RHDP card above will just prepare for you a base environment (OCP+AI). You still need to deploy the demo by running the installation process described below.<br></p>
</li>
<li>
<p>The provisioning process takes around 80-90 minutes to complete. You need to wait its completion before proceeding to the demo installation.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p><br></p>
</div>
</li>
<li>
<p>Alternatively, if you don&#8217;t have access to RHDP, ensure you have an <em>OpenShift</em> environment available and install <em>Red Hat OpenShift AI</em>.</p>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
  You can obtain one by deploying the trial version available at <a href="https://www.redhat.com/en/technologies/cloud-computing/openshift/try-it" target="_blank" rel="noopener">Try Red Hat OpenShift</a>.
</td>
</tr>
</table>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><br></p>
</div>
</div>
<div class="sect2">
<h3 id="_install_the_demo_using_docker_or_podman"><a class="anchor" href="#_install_the_demo_using_docker_or_podman"></a><a class="link" href="#_install_the_demo_using_docker_or_podman">3.3. Install the demo using <em>Docker</em> or <em>Podman</em></a></h3>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>For more installation tips and alternative options to <em>Docker</em> and <em>Podman</em>, look at the <a href="https://github.com/brunoNetId/sp-edge-to-cloud-data-pipelines-demo/blob/main/README.md" target="_blank" rel="noopener">README</a> file in the demo&#8217;s GitHub repository.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Ensure your base <em>OpenShift+AI</em> environment is ready and you have all the connection and credential details with you.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Clone this GitHub repository:</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">git clone https://github.com/brunoNetId/sp-edge-to-cloud-data-pipelines-demo.git</code></pre>
</div>
</div>
</li>
<li>
<p>Change directory to the root of the project.</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">cd sp-edge-to-cloud-data-pipelines-demo</code></pre>
</div>
</div>
</li>
<li>
<p>Configure the <code>KUBECONFIG</code> file to use (where kube details are set after login).</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">export KUBECONFIG=./ansible/kube-demo</code></pre>
</div>
</div>
</li>
<li>
<p>Obtain and execute your login command from <em>OpenShift</em>'s console, or use the <code>oc</code> command line below to access your cluster.</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">oc login --username="admin" --server=https://(...):6443 --insecure-skip-tls-verify=true</code></pre>
</div>
</div>
<div class="paragraph">
<p>Replace the <code>--server</code> url with your own cluster API endpoint.</p>
</div>
<div class="paragraph">
<p><br></p>
</div>
</li>
<li>
<p>Run the Playbook with Docker/Podman</p>
<div class="ulist">
<ul>
<li>
<p>First, read the note below</p>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>If your system is SELinux enabled, you&#8217;ll need to label the project directory to allow docker/podman to access it. Run the command:</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">sudo chcon -Rt svirt_sandbox_file_t $PWD</code></pre>
</div>
</div>
<div class="paragraph">
<p>The error you may get if SELinux blocks the process would be similar to:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>ERROR! the playbook: ./ansible/install.yaml could not be found</pre>
</div>
</div>
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Then, to run with Docker:</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">docker run -i -t --rm --entrypoint /usr/local/bin/ansible-playbook \
-v $PWD:/runner \
-v $PWD/ansible/kube-demo:/home/runner/.kube/config \
quay.io/agnosticd/ee-multicloud:v0.0.11  \
./ansible/install.yaml</code></pre>
</div>
</div>
</li>
<li>
<p>Or, to run With Podman:</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">podman run -i -t --rm --entrypoint /usr/local/bin/ansible-playbook \
-v $PWD:/runner \
-v $PWD/ansible/kube-demo:/home/runner/.kube/config \
quay.io/agnosticd/ee-multicloud:v0.0.11  \
./ansible/install.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><br></p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_walkthrough_guide"><a class="anchor" href="#_walkthrough_guide"></a><a class="link" href="#_walkthrough_guide">4. Walkthrough guide</a></h2>
<div class="sectionbody">
<div class="paragraph">
<p>The guide below will help you to familiarise with the main components in the demo, and how to operate it to trigger the actions&#8230;&#8203;</p>
</div>
<div class="sect2">
<h3 id="_quick_topology_overview"><a class="anchor" href="#_quick_topology_overview"></a><a class="link" href="#_quick_topology_overview">4.1. Quick Topology Overview</a></h3>
<div class="paragraph">
<p>Open your <em>OpenShift</em> console with your given admin credentials and open the <em>Topology View</em> to inspect the main systems deployed in the <em>Edge1</em> namespace.</p>
</div>
<div class="paragraph">
<p>Following the illustration below:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Select from the left menu the Developer view</p>
</li>
<li>
<p>Search in the filter textbox by <code>edge1</code></p>
</li>
<li>
<p>Select the project <code>edge1</code></p>
</li>
<li>
<p>Make sure you display the <em>Topologoy</em> view (left menu)</p>
</li>
</ol>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/12-topology-edge1.png" alt="12 topology edge1">
</div>
</div>
<div class="paragraph">
<p>In the image above you&#8217;ll see the main applications deployed in the <em>Edge</em> zone:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Shopper</strong>: This is the main AI-powered application. The application exposes a smart device App you can open from your phone or browser. The application integrates with the <em>AI/ML Model Server</em> to request inferences, and also with the <em>Price Engine</em> to obtain price information from the product catalogue.</p>
<div class="paragraph">
<p>The App has two main uses:</p>
</div>
<div class="openblock">
<div class="content">
<div class="ulist">
<ul>
<li>
<p>Customers/Shoppers use it to obtain information about product, in this context of this demo, the price tag of a product.</p>
</li>
<li>
<p>Staff members can generate training data by capturing images for new products.</p>
<div class="paragraph">
<p></p>
</div>
</li>
</ul>
</div>
</div>
</div>
</li>
<li>
<p><strong>Model Server</strong>: This is the AI/ML engine running inferences and capable of recognizing products. It exposes an API for clients to send an image, and responds with the product name identified. The Model Server is composed of:</p>
<div class="ulist">
<ul>
<li>
<p>TensorFlow model server: the AI/ML brain executor.</p>
</li>
<li>
<p>Minio instance (from where the models are loaded).</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Price Engine</strong>: This application keeps the product catalogue and contains the pricing information. It exposes an API to obtain product information where the price tag is included.</p>
</li>
<li>
<p><strong>Manager</strong>: This integration runs in the background monitoring the availability of new model versions in the Core Data Centre (<em>Central</em>). When a new model version is available it is responsible to obtain it and push it to the Model Server.</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
You&#8217;ll find in the <em>Edge</em> project other systems also deployed, but we won&#8217;t dive into them as they are of less importance to the main story. Some mentions will be done to them when the context is relevant.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><br></p>
</div>
</div>
<div class="sect2">
<h3 id="_play_with_the_smart_application"><a class="anchor" href="#_play_with_the_smart_application"></a><a class="link" href="#_play_with_the_smart_application">4.2. Play with the Smart Application</a></h3>
<div class="paragraph">
<p>Let&#8217;s interact with the <em>Edge</em> environment from the Smart Application to see the system in action.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The model server has been preloaded with a first version of the model (<strong>v1</strong>), pre-trained to only recognise two types of tea:</p>
</div>
<div class="paragraph">
<p><em>Earl Grey Tea</em> and <em>Lemon Tea</em>.
<span class="image"><img src="_images/14-tea-earl-grey.png" alt="14 tea earl grey" width="10%"></span>
<span class="image"><img src="_images/15-tea-lemon.png" alt="15 tea lemon" width="10%"></span></p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>First, let&#8217;s run some negative tests by taking random pictures of objects around you. Because <strong>v1</strong> has not been trained to identify those objects, the system will not be able to provide a price for them and will respond with the label <em>"Other"</em> (as in <em>'product not identified'</em>).</p>
</div>
<div class="paragraph">
<p>Open the <em>Shopper App</em> by clicking on the <em>Route</em> exposed by the application pod, as shown in the picture below:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/13-open-shopper-app.png" alt="13 open shopper app" width="30%">
</div>
</div>
<div class="paragraph">
<p>This action will open a new tab in your browser presenting the app&#8217;s landing page.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
You can also open the application from your smart phone if you share its URL to your device.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Next, follow the actions below illustrated to run some inferences. Observe the response on your screen every time you send an image.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/16-detection-mode.jpg" alt="16 detection mode">
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The App allows you to simulate an image transmittion via <em>HTTP</em>, as would tipically apps interact with backend servers, or via <em>MQTT</em>, a lightweight messaging protocol, commonly used in the <em>IoT</em>, preferable for edge devices constrained by network bandwidth, energy consumption and CPU power.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
In the demo, the App uses an <em>MQTT</em> library that uses <em>Websockets</em> to connect to the <em>AMQ Broker</em> deployed in the <em>Edge</em> project. The <em>Camel</em> application connects via <em>MQTT</em> to pick up the messages, process them and respond, also via <em>MQTT</em>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>You should see in your display the following response:</p>
</div>
<div class="paragraph">
<p><span class="image"><img src="_images/17-result-other.png" alt="17 result other" width="20%"></span></p>
</div>
<div class="paragraph">
<p>It means it wasn&#8217;t able to identify the object.</p>
</div>
<div class="paragraph">
<p>Let&#8217;s now run some positive inferences. We have included in the GitHub repository images that have been used as input to train the model.</p>
</div>
<div class="paragraph">
<p>Make sure you operate from your computer&#8217;s browser, and this time click on the button <code>Pick from Device</code> instead. This action will open your system&#8217;s file chooser.</p>
</div>
<div class="paragraph">
<p>To pick the images to test with, navigate to the following project path:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>sp-edge-to-cloud-data-pipelines-demo/demo</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>where you will find the following images:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>tea-earl-grey.jpg</code></p>
</li>
<li>
<p><code>tea-lemon.jpg</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Try them out. You should obtain positive results with the following responses:</p>
</div>
<table class="tableblock frame-all grid-all fit-content">
<colgroup>
<col>
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>Earl Grey Tea: 3.99</em></p></td>
</tr>
</tbody>
</table>
<table class="tableblock frame-all grid-all fit-content">
<colgroup>
<col>
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>Lemon Tea: 4.99</em></p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><br></p>
</div>
<div class="paragraph">
<p>In the section that follows you will train a new version of the model (<strong>v2</strong>) to include a third type of tea, <em>Bali Green Tea</em>, which <strong>v1</strong> does not identify.</p>
</div>
<div class="paragraph">
<p>Before you continue to the next section, run one last negative to confirm the model does not know about it.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Enter the <em>Detection Mode</em> in your Smart App</p>
</li>
<li>
<p>Click on the <code>Pick from Device</code> button.</p>
</li>
<li>
<p>Navigate to the following project path:</p>
<div class="openblock">
<div class="content">
<div class="ulist">
<ul>
<li>
<p><code>sp-edge-to-cloud-data-pipelines-demo/demo</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>where you will find the image:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>tea-bali.jpg</code></p>
</li>
</ul>
</div>
</div>
</div>
</li>
<li>
<p>Select and send it via HTTP or MQTT</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>You should obtain the negative response:</p>
</div>
<div class="paragraph">
<p><span class="image"><img src="_images/17-result-other.png" alt="17 result other" width="20%"></span></p>
</div>
<div class="paragraph">
<p><br></p>
</div>
</div>
<div class="sect2">
<h3 id="_train_a_new_product"><a class="anchor" href="#_train_a_new_product"></a><a class="link" href="#_train_a_new_product">4.3. Train a new product</a></h3>
<div class="paragraph">
<p>The <em>Edge</em> environment has been pre-loaded with training data. This will make it easy for you to produce a second version of the model (<strong>v2</strong>) which you can try out.</p>
</div>
<div class="paragraph">
<p>You can visualise the training data by opening <em>Minio</em>'s UI and browsing the <code>data</code> S3 bucket. Or you can use the following online S3 browser which nicely displays all the images to use for training, head to:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://www.filestash.app/s3-browser.html" target="_blank" rel="noopener">Online S3 browser</a></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>And enter the following details:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Access Key ID: <code>minio</code></p>
</li>
<li>
<p>Secret Access ID: <code>minio123</code></p>
</li>
<li>
<p>Advanced &gt;</p>
<div class="ulist">
<ul>
<li>
<p>Endpoint: [Minio&#8217;s URL]</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>You can obtain your Minio instance URL by executing the following <code>oc</code> command:</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">oc get route minio-api -o custom-columns=HOST:.spec.host -n edge1</code></pre>
</div>
</div>
<div class="paragraph">
<p>Your connection details on screen should look similar to the picture below:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/18-s3-connect.png" alt="18 s3 connect" width="40%">
</div>
</div>
<div class="paragraph">
<p>Click <code>CONNECT</code>, and select the folder (bucket) <code>data</code>.</p>
</div>
<div class="paragraph">
<p>Navigate to the folder <code>images/tea-green</code> where you should find all the training images you&#8217;re about to use:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/19-s3-data.jpg" alt="19 s3 data" width="50%">
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
This collection of training data was captured during a live demonstration where the audience participated in generating the images.
</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
A quick reminder: <strong>v1</strong> does not know about this type of tea, it only knows about <em>Earl Grey Tea</em> and <em>Lemon Tea</em>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>This new product is <em>"(Bali) Green Tea"</em> and is labelled as <code>tea-green</code>. The price engine is also preconfigured with a specific price tag for this product.</p>
</div>
<div class="paragraph">
<p>We can trigger the training process from a hidden administrative page the <em>Shopper</em> application includes. Use the following command to obtain the admin page URL address:</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">echo "https://`oc get route camel-edge -n edge1 --template={{.spec.host}}`/admin.html"</code></pre>
</div>
</div>
<div class="paragraph">
<p>Copy the resulting URL address and use it in a new tab in your computer&#8217;s browser.</p>
</div>
<div class="paragraph">
<p>A monitoring view will display all the playing parts in the demo. You will already be familiar with most of the parts shown on the monitoring view (which map to those visible from your <em>Topology</em> view from the <em>OpenShift</em>'s console):</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/20-monitor-admin-view.jpg" alt="20 monitor admin view">
</div>
</div>
<div class="paragraph">
<p><br></p>
</div>
<div class="sect3">
<h4 id="_review_the_data_acquisition_phase"><a class="anchor" href="#_review_the_data_acquisition_phase"></a><a class="link" href="#_review_the_data_acquisition_phase">4.3.1. Review the <em>Data Acquisition</em> phase</a></h4>
<div class="paragraph">
<p>Prior to initiating the training process, and now that you&#8217;re familiar with the monitoring view, let&#8217;s rewind a little and remind ourselves what processes are involved in the <em>Data Acquisition</em> phase.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
We are bypassing the ingestion (<em>Data Acquisition</em>) phase to speed up the process of producing a second version of the model. Later you will participate in generating your own training data to produce a third version of the model.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The illustration below shows how, during the <em>Data Acquisition</em> phase, training data is generated from devices and pushed to the system.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/23-monitor-admin-ingestion.jpg" alt="23 monitor admin ingestion">
</div>
</div>
<div class="paragraph">
<p>Each image, captured by a worker and sent over the network, is received and pushed to local S3 storage on the <em>Edge</em>. This phase may take a certain period of time until a large number of images is collected. To maximise accuracy you ideally want to train the model with vast amounts of training data.</p>
</div>
<div class="paragraph">
<p><br></p>
</div>
</div>
<div class="sect3">
<h4 id="_enter_the_training_phase"><a class="anchor" href="#_enter_the_training_phase"></a><a class="link" href="#_enter_the_training_phase">4.3.2. Enter the <em>Training</em> phase</a></h4>
<div class="paragraph">
<p>To initiate the training process, click the button on the upper-left side of the window:</p>
</div>
<div class="paragraph">
<p><span class="image"><img src="_images/21-monitor-admin-button.jpg" alt="21 monitor admin button" width="20%"></span></p>
</div>
<div class="paragraph">
<p>After you click <code><em>Train Data</em></code>, you&#8217;ll see in the monitoring view a series of live animations illustrating the actions actually taking place in the platform. The following enumeration describes the process:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The click action triggers a signal that a <em>Camel</em> integration (<em>Manager</em>) picks up.</p>
</li>
<li>
<p>The <em>Manager</em> reads all the training data from the S3 bucket where it resides and packages it as a ZIP container.</p>
</li>
<li>
<p>The <em>Manager</em> invokes an API served from the Core Data Center (<em>Central</em>) to send the ZIP data.</p>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<em>Edge</em> and <em>Core</em> are connected via <em>Service Interconnect</em>. Both regions are running an instance of <em>Skupper</em> to form virtual services which securely interconnect systems from both sides.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>The system <em>Feeder</em> (<em>Camel</em>) exposing the above requested API, unpacks the ZIP container and pushes the data to a central S3 service used as the storage system (<em>ODF</em>) for training new models.</p>
</li>
<li>
<p>The same system <em>Feeder</em> sends a signal via <em>Kafka</em> to announce the arrival of new training data to be processed.</p>
</li>
<li>
<p>The system <em>Delivery</em> (Camel) is subscribed to the announcements topic. It receives the Kafka signal and triggers the Pipeline responsible the create the a new model version.</p>
</li>
<li>
<p>The pipeline (<em>Tekton</em>) kicks off. It reads from the S3 storage system all the training data available and executes the Data Science notebooks based on <em>TensorFlow</em></p>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The entire execution of the pipeline may take between 2-5 minutes depending on the resources allocated in the environment.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>At the end of the pipeline process, a new model is pushed to an edge-dedicated topic where new model placed.</p>
</li>
<li>
<p>A copy of the new model version is also pushed to a Model repository. In this demo, just another S3 bucket, where a history of model versions is kept.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>All the steps above form part of the <em>Data Preparation and Modelling</em> phase (described in the <em>Architecture</em> chapter) and are well illustrated in the diagram below:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/22-monitor-admin-pipeline.jpg" alt="22 monitor admin pipeline">
</div>
</div>
<div class="paragraph">
<p><br></p>
</div>
</div>
<div class="sect3">
<h4 id="_the_delivery_phase"><a class="anchor" href="#_the_delivery_phase"></a><a class="link" href="#_the_delivery_phase">4.3.3. The <em>Delivery</em> phase</a></h4>
<div class="paragraph">
<p>The end-to-end process is not done yet. It then enters into the <em>Delivery</em> phase. The new model has now been pushed to an S3 bucket <code>edge1-ready</code> that is being monitored by an integration point on the Edge (<em>Manager</em>)</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<em>Edge</em> and <em>Core</em> are connected via <em>Service Interconnect</em>. Both regions are running an instance of <em>Skupper</em> to form virtual services which securely interconnect systems from both sides.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>When the <em>Tekton</em> pipeline uploads the new model to the S3 bucket, the <em>Edge Manager</em> notices the artifacts and initiates the download of the model and hot deploys it in the TensorFlow model server, as shown in the picture below:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/24-monitor-admin-delivery.jpg" alt="24 monitor admin delivery">
</div>
</div>
<div class="paragraph">
<p>The AI/ML engine, powered by the <em>TensorFlow Model Server</em>, reacts to the new version (<strong>v2</strong>), now available in its local S3 bucket, and initiates a hot-deployment. It loads the new version and discards the old one that was held in memory. This process happens without service interruption. Clients sending inference requests inadvertently start obtaining results computed with the new hot-deployed version (<strong>v2</strong>).</p>
</div>
<div class="paragraph">
<p><br></p>
</div>
</div>
<div class="sect3">
<h4 id="_the_inferencing_phase"><a class="anchor" href="#_the_inferencing_phase"></a><a class="link" href="#_the_inferencing_phase">4.3.4. The <em>Inferencing</em> phase</a></h4>
<div class="paragraph">
<p>The platform keeps running its live services at all times. Customers (shoppers) and workers interact with the platform while, in the background, new models are continuously being trained, delivered and deployed.</p>
</div>
<div class="paragraph">
<p>The demo&#8217;s inferencing phase is illustrated in the picture below:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/25-monitor-admin-inferencing.jpg" alt="25 monitor admin inferencing">
</div>
</div>
<div class="paragraph">
<p>You should already be familiar with the flows above. You had the chance to perform some positive/negative tests via HTTP/MQTT. The <em>Shopper</em> application (<em>Camel</em>) first sends an inference request against the AI/ML engine to identify the product, then:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>If the AI engine identifies the product, it provides a label, for example <code>tea-lemon</code>, and <em>Camel</em> calls the Price Engine to obtain a price tag for that product. The image is also kept in S3 storage as it may be used to improve the accuracy of future models.</p>
</li>
<li>
<p>If the AI engine does not identify the product (negative response <code>other</code>), Camel directly pushes the image to an S3 bucket of unidentified images. This may help Data Scientists to analyse the data.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>You&#8217;ve already interacted with the application using the demo App. Let&#8217;s use it again to try out the newly trained version.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Before continuing, make sure your pipeline has finished execution. You can use your <em>OpenShift</em>'s console to inspect the state of the <em>PipelineRun</em>, or you can execute the following <code>oc</code> command to monitor it:</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">oc get pipelinerun -n tf</code></pre>
</div>
</div>
<div class="paragraph">
<p>When the pipeline completes successfully, you should see the following output:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>NAME                    SUCCEEDED   REASON      STARTTIME   COMPLETIONTIME
train-model-run-ljrdk   True        Succeeded   92m         89m</pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Go back to the Smart Application in your browser and this time, with the newly trained model (<strong>v2</strong>), send the <em>Bali Green Tea</em> image that <strong>v1</strong> didn&#8217;t know about.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Enter the <em>Detection Mode</em> in your Smart App</p>
</li>
<li>
<p>Click on the <code>Pick from Device</code> button.</p>
</li>
<li>
<p>Navigate to the following project path:</p>
<div class="openblock">
<div class="content">
<div class="ulist">
<ul>
<li>
<p><code>sp-edge-to-cloud-data-pipelines-demo/demo</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>where you will find the image:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>tea-bali.jpg</code></p>
</li>
</ul>
</div>
</div>
</div>
</li>
<li>
<p>Select and send it via HTTP or MQTT</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>This time, the product should be identified, and you should obtain a price tag as follows:</p>
</div>
<table class="tableblock frame-all grid-all fit-content">
<colgroup>
<col>
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>(Bali) Green Tea: 2.49</em></p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>Bravo !! you have completed the full cycle.</p>
</div>
<div class="paragraph">
<p><br></p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_create_your_own_product"><a class="anchor" href="#_create_your_own_product"></a><a class="link" href="#_create_your_own_product">4.4. Create your own product</a></h3>
<div class="paragraph">
<p>Up until now, you&#8217;ve played with pre-configured systems, and pre-loaded data, to train <strong>v2</strong>. It is time to go one level up. You will configure the system to create a new entry in the product catalogue, generate training data for the new product, train the new model <strong>v3</strong>, and run live inferences against it.</p>
</div>
<div class="sect3">
<h4 id="_configure_the_price_engine"><a class="anchor" href="#_configure_the_price_engine"></a><a class="link" href="#_configure_the_price_engine">4.4.1. Configure the <em>Price Engine</em></a></h4>
<div class="paragraph">
<p>First things first, head to your OpenShift console and find the following <em>ConfigMap</em>:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>catalogue</code><br>
This configmap is owned by the <em>Price Engine</em> and configures all the products available.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Edit the catalogue to include a new product.<br>
Follow the steps below to find your way:</p>
</div>
<div class="paragraph">
<p><span class="image"><img src="_images/26-configure-configmap.jpg" alt="26 configure configmap"></span></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>From the console (<code>edge1</code> project), click on the menu option <code>ConfigMaps</code></p>
</li>
<li>
<p>From the list of displayed configmaps, select <code>catalogue</code>.</p>
</li>
<li>
<p>You&#8217;ll find the option to <code>Edit ConfigMap</code> from the top right-right corner of the console.</p>
<div class="ulist">
<ul>
<li>
<p>Click Actions &#8594; Edit ConfigMap</p>
</li>
</ul>
</div>
</li>
<li>
<p>Locate the lower-right corner of the text area</p>
</li>
<li>
<p>Click and drag the corner downwards to expand the text area.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The JSON data configures the products. You&#8217;ll find in the definition all the products you have been playing with.</p>
</div>
<div class="paragraph">
<p>Now include in the configuration a new product.
If one does not come to mind, use the JSON data below to configure a <code>Computer Mouse</code> product:</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json hljs" data-lang="json">    {
      "item": "computer-mouse",
      "label": "Computer Mouse",
      "price": 19.99
    },</code></pre>
</div>
</div>
<div class="paragraph">
<p>Copy the JSON node above and paste it in the <em>ConfigMap</em>.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
Make sure your JSON document is valid after finishing editing. Make sure commas (<code>,</code>) are in the right place.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Click <code>Save</code>.</p>
</div>
<div class="paragraph">
<p>Now you need to restart the <em>Price Engine</em>. You can simply kill the pod and <em>Kubernetes</em> will restart a new one that will read the new <em>ConfigMap</em> value.</p>
</div>
<div class="paragraph">
<p>You can use the web Console to do so, or execute the <code>oc</code> command below:</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">oc delete pod -n edge1 `oc get pods -n edge1 | grep price | awk '{print $1}'`</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can validate, by inspecting the logs, the new started pod has loaded the new product catalogue. Again, you can use the web console, or execute from your terminal the command below:</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">oc logs svc/price-engine -n edge1</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the output logs from the command above, you should find the value <code>"Computer Mouse"</code>. Your logs should look similar to:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">... INFO  [pri.xml:74] (Camel (camel-1) thread #1 - timer://products) ["Earl Grey Tea", "(Bali) Green Tea", "Lemon Tea", "Computer Mouse", "Other"]</code></pre>
</div>
</div>
<div class="paragraph">
<p>Next, you need to configure the Smart Application to allow selecting the new product for training.</p>
</div>
<div class="paragraph">
<p><br></p>
</div>
</div>
<div class="sect3">
<h4 id="_configure_the_shopper_application"><a class="anchor" href="#_configure_the_shopper_application"></a><a class="link" href="#_configure_the_shopper_application">4.4.2. Configure the <em>Shopper</em> application</a></h4>
<div class="paragraph">
<p>You need to perform a similar operation. From your OpenShift console, find the following <em>ConfigMap</em>:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>shopper-training-options</code><br>
This ConfigMap is owned by the <em>Shopper</em> (<em>Camel</em>) integration and configures all the trainable products from the App&#8217;s '<em>Ingestion Mode</em>' option (Data Acquisition).</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Follow the same steps as previously done to find the ConfigMap and open the Edit window.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>From the console (<code>edge1</code> project), click on the menu option <code>ConfigMaps</code></p>
</li>
<li>
<p>From the list of displayed configmaps, select <code>shopper-training-options</code>.</p>
</li>
<li>
<p>You&#8217;ll find the option to <code>Edit ConfigMap</code> from the top right-right corner of the console.</p>
<div class="ulist">
<ul>
<li>
<p>Click Actions &#8594; Edit ConfigMap</p>
</li>
</ul>
</div>
</li>
<li>
<p>Locate the lower-right corner of the text area</p>
</li>
<li>
<p>Click and drag the corner downwards to expand the text area.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Replace the old product by the new one.<br>
If you used the previous sample configuration for the <em>"Computer Mouse"</em>, copy the value below and replace the old product in your text area:</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json hljs" data-lang="json">[
  {
      "item": "computer-mouse",
      "label": "Computer Mouse"
  }
]</code></pre>
</div>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
You can also add a sequence of products. Instead of deleting the old product, you can add the new one separated with a comma.
</td>
</tr>
</table>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
Make sure your JSON document is valid after finishing editing. Make sure commas (<code>,</code>) are in the right place.<br>
Also, the values in this configuration need to match those in the product catalogue.<br>
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
This information configures display options in the Smart App. Notice you don&#8217;t define a price tag here.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Click <code>Save</code>.</p>
</div>
<div class="paragraph">
<p>Now you need to restart the <em>Shopper</em> application. You can simply kill the pod and <em>Kubernetes</em> will restart a new one that will read the new <em>ConfigMap</em> value.</p>
</div>
<div class="paragraph">
<p>You can use the Web Console to do so, or execute the <code>oc</code> command below:</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">oc delete pod -n edge1 `oc get pods -n edge1 | grep shopper | awk '{print $1}'`</code></pre>
</div>
</div>
<div class="paragraph">
<p>You&#8217;re now ready to generate and ingest training data.</p>
</div>
<div class="paragraph">
<p><br></p>
</div>
</div>
<div class="sect3">
<h4 id="_generate_training_data"><a class="anchor" href="#_generate_training_data"></a><a class="link" href="#_generate_training_data">4.4.3. Generate Training Data</a></h4>
<div class="paragraph">
<p>In this section you will use the web based Smart App to capture images and push them to the platform. The easiest way to capture images is to use your smart phone.</p>
</div>
<div class="paragraph">
<p>Share the URL&#8217;s address with your phone and open it with the device&#8217;s browser.</p>
</div>
<div class="paragraph">
<p>Follow the steps illustrate below to capture and send images:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/27-ingestion-mode.jpg" alt="27 ingestion mode">
</div>
</div>
<div class="paragraph">
<p>Above, in step 2 you should find the option that you configured earlier. If you used the sample JSON snippets you should find on your screen the option:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Computer Mouse</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Now, take various pictures and push the as indicated. Change angles, rotate the object, flip the object. The more data you push, the more accurate your model will become.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
AI/ML models are generally trained with thousands/millions of pictures to achieve the best results. However, with only few images for experimentation, it should work too.
</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
If you open the monitoring view while pushing data from your smart device, you should see live interactions with the <em>Edge</em> systems.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>When you&#8217;re done with the <em>Ingestion</em> phase, you should end up with a collection similar to the picture below:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/28-data-computer-mouse.jpg" alt="28 data computer mouse" width="50%">
</div>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
Use the same S3 browser to visualise the data.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><br></p>
</div>
</div>
<div class="sect3">
<h4 id="_kick_off_the_training_process"><a class="anchor" href="#_kick_off_the_training_process"></a><a class="link" href="#_kick_off_the_training_process">4.4.4. Kick-off the training process</a></h4>
<div class="paragraph">
<p>As you did earlier, from the administrative page, trigger the training process using the UI button.</p>
</div>
<div class="paragraph">
<p><span class="image"><img src="_images/21-monitor-admin-button.jpg" alt="21 monitor admin button" width="20%"></span></p>
</div>
<div class="paragraph">
<p>Click <code>Train Data</code>.</p>
</div>
<div class="paragraph">
<p>Verify the pipeline is running and wait for its completion.<br>
Use the command:</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">oc get pipelinerun -n tf</code></pre>
</div>
</div>
<div class="paragraph">
<p>You should obtain something similar to:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>NAME                    SUCCEEDED   REASON      STARTTIME   COMPLETIONTIME
train-model-run-ljrdk   True        Succeeded   6h23m       6h20m
train-model-run-lms4q   Unknown     Running     9s</pre>
</div>
</div>
<div class="paragraph">
<p>where you can see the previous <em>PipelineRun</em> in status <code>Succeeded</code>, and the new one <code>Running</code>.</p>
</div>
<div class="paragraph">
<p>When the pipeline completes, go back to your App&#8217;s <code>Detection Mode</code> and try the new product out. If you trained your computer mouse, take a picture and send it.</p>
</div>
<div class="paragraph">
<p>You should obtain a price tag for your mouse:</p>
</div>
<table class="tableblock frame-all grid-all fit-content">
<colgroup>
<col>
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>Computer Mouse</em>: <em>19.99</em></p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>Well done! You have iterated the <em>Product Catalogue</em> to include new articles on offer.</p>
</div>
</div>
</div>
</div>
</div>
<nav class="pagination">
  <span class="prev"><a href="02-architecture.html" class="query-params-link">2. Architecture</a></span>
  <span class="next"><a href="04-devresources.html" class="query-params-link">4. Developer Resources</a></span>
</nav>
</article>
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
  </div>
</main>
</div>
<footer class="footer">
  <img
          src="../_/img/app-services-logo.png" height="40px" alt="Cloud Native Architecture Solution Patterns"  href="https://redhat.com" ></a>
</footer><script src="../_/js/vendor/clipboard.js"></script>
<script src="../_/js/site.js"></script>
<script async src="../_/js/vendor/highlight.js"></script>
  </body>
</html>
